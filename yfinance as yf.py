import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error
import matplotlib.pyplot as plt

# ğŸ”§ í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'Malgun Gothic'
plt.rcParams['axes.unicode_minus'] = False

# ì¢…ëª©ë³„ ê²½ë¡œ
file_paths = {
    "AAPL": "C:/Users/blue0/Downloads/AAPL.csv",
    "MSFT": "C:/Users/blue0/Downloads/MSFT.csv",
    "NVDA": "C:/Users/blue0/Downloads/NVDA.csv"
}

# ì‹œê³„ì—´ ë°ì´í„° êµ¬ì„± í•¨ìˆ˜
def create_dataset(data, look_back=30):
    X, Y = [], []
    for i in range(len(data) - look_back):
        X.append(data[i:i+look_back, :])
        Y.append(data[i+look_back, 0])
    return np.array(X), np.array(Y)

# ESN ëª¨ë¸ ì •ì˜
class ESN(nn.Module):
    def __init__(self, input_size, reservoir_size=100, spectral_radius=0.9):
        super(ESN, self).__init__()
        self.Win = torch.empty(reservoir_size, input_size).uniform_(-0.5, 0.5)
        W = torch.empty(reservoir_size, reservoir_size).uniform_(-0.5, 0.5)
        eigvals = torch.linalg.eigvals(W).abs()
        W *= spectral_radius / eigvals.max()
        self.W = W
        self.Wout = nn.Linear(reservoir_size, 1)

    def forward(self, X):
        batch_size, seq_len, _ = X.size()
        h = torch.zeros(batch_size, self.W.shape[0])
        for t in range(seq_len):
            u = X[:, t, :]
            h = torch.tanh(torch.matmul(u, self.Win.T) + torch.matmul(h, self.W.T))
        return self.Wout(h)

# ì¢…ëª© ë°˜ë³µ
for stock, path in file_paths.items():
    print(f"\n===== {stock} ì˜ˆì¸¡ ì‹œì‘ =====")

    df = pd.read_csv(path).dropna()
    df.set_index('Date', inplace=True)
    scaler = MinMaxScaler()
    scaled = scaler.fit_transform(df)

    X, Y = create_dataset(scaled, look_back=30)
    X_tensor = torch.tensor(X, dtype=torch.float32)
    Y_tensor = torch.tensor(Y, dtype=torch.float32).view(-1, 1)

    split = int(len(X_tensor) * 0.8)
    X_train, X_test = X_tensor[:split], X_tensor[split:]
    Y_train, Y_test = Y_tensor[:split], Y_tensor[split:]

    model = ESN(input_size=X_train.shape[2])
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.Wout.parameters(), lr=0.001)

    for epoch in range(100):
        model.train()
        output = model(X_train)
        loss = criterion(output, Y_train)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    print(f"{stock} ìµœì¢… í•™ìŠµ ì†ì‹¤: {loss.item():.6f}")

    model.eval()
    with torch.no_grad():
        predictions = model(X_test).numpy()
        ground_truth = Y_test.numpy()

    pred_prices = scaler.inverse_transform(
        np.concatenate([predictions, X_test[:, -1, 1:].numpy()], axis=1)
    )[:, 0]
    true_prices = scaler.inverse_transform(
        np.concatenate([ground_truth, X_test[:, -1, 1:].numpy()], axis=1)
    )[:, 0]

    # smoothing
    smooth_pred = pd.Series(pred_prices).rolling(window=5).mean()

    # MAE, RMSE ê³„ì‚°
    mae = mean_absolute_error(true_prices, pred_prices)
    rmse = np.sqrt(mean_squared_error(true_prices, pred_prices))

    print(f"[{stock}] MAE: {mae:.4f}, RMSE: {rmse:.4f}")

    plt.figure(figsize=(12, 6))
    plt.plot(true_prices, label='ì‹¤ì œ ì¢…ê°€')
    plt.plot(smooth_pred, label='ì˜ˆì¸¡ ì¢…ê°€ (ì´ë™í‰ê· )', color='orange')
    plt.title(f"{stock} ì¢…ê°€ ì˜ˆì¸¡ (ESN)")
    plt.xlabel("ì‹œê°„")
    plt.ylabel("ê°€ê²©")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()
